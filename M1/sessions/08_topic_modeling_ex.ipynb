{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18298de9",
   "metadata": {},
   "source": [
    "# Topic Modeling: Organizing Unlabeled CVs with LDA\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **Topic Modeling** using **Latent Dirichlet Allocation (LDA)** to organize unlabeled CVs (resumes) by automatically discovering hidden topics. Unlike supervised classification, topic modeling works with completely unlabeled data, making it ideal for organizing large document collections without manual labeling. You'll learn how to apply LDA to discover topics, interpret results, and organize documents based on their dominant topics.\n",
    "\n",
    "> \"The best way to find a needle in a haystack is to organize the haystack first.\"\n",
    "\n",
    "**The Problem**: You have a folder full of CVs—unlabeled, unorganized. You need to find candidates for specific roles, but manually reading through hundreds of CVs is impossible.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Understand what Topic Modeling is and why it's useful for unsupervised document organization\n",
    "- Learn how LDA (Latent Dirichlet Allocation) discovers hidden topics in text collections\n",
    "- Apply LDA to organize unlabeled documents automatically\n",
    "- Interpret topic modeling results by examining top words and document-topic distributions\n",
    "- Organize documents into folders based on their dominant topics\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Introduction to Topic Modeling** - What it is and why it's useful\n",
    "2. **What is LDA?** - Understanding Latent Dirichlet Allocation\n",
    "3. **The Pipeline** - Complete workflow from data loading to organization\n",
    "4. **Step 1: Loading Data** - Reading CVs from JSON files\n",
    "5. **Step 2: Preprocessing** - Cleaning and preparing text\n",
    "6. **Step 3: Vectorization** - Converting text to document-term matrix\n",
    "7. **Step 4: Training LDA** - Discovering topics automatically\n",
    "8. **Step 5: Analyzing Results** - Interpreting discovered topics\n",
    "9. **Step 6: Organizing Documents** - Creating folders and organizing CVs by topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded0fed",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "**Topic Modeling** is an **unsupervised learning** task that discovers hidden topics in a collection of unlabeled documents. Unlike classification (which requires labeled data), topic modeling finds patterns automatically.\n",
    "\n",
    "**Example applications:**\n",
    "- **Organizing unlabeled documents**: Group CVs by field (AI/ML, Data Analysis, etc.) without manual labeling\n",
    "- **Understanding large text collections**: Discover what themes exist in news archives, research papers, or social media\n",
    "- **Content recommendation**: Find documents similar to a given document based on topic similarity\n",
    "\n",
    "**Why it's useful:**\n",
    "- No labels needed: works with completely unlabeled data\n",
    "- Interpretable: topics are defined by their top words, making them understandable\n",
    "- Scalable: can process large document collections\n",
    "- Flexible: number of topics can be adjusted based on the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f61c3f",
   "metadata": {},
   "source": [
    "## What is LDA?\n",
    "\n",
    "**Latent Dirichlet Allocation (LDA)** is a probabilistic model that discovers hidden topics in a collection of documents.\n",
    "\n",
    "**Key idea**: \n",
    "- Each document is a **mixture of topics** (e.g., 70% AI/ML, 20% Data Analysis, 10% Software Engineering)\n",
    "- Each topic is a **distribution over words** (e.g., Topic 1: 30% \"PyTorch\", 25% \"TensorFlow\", 20% \"NLP\"...)\n",
    "- LDA discovers these topics automatically by finding words that co-occur together\n",
    "\n",
    "**For our CVs**: LDA will discover topics like \"AI/ML\", \"Data Analysis\", \"Big Data\" by looking at which words appear together, then assign each CV to the most relevant topic(s).\n",
    "\n",
    "**Reference**: Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). [Latent dirichlet allocation](https://dl.acm.org/doi/10.5555/944919.944937). *Journal of machine Learning research*, 3(Jan), 993-1022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf82c0",
   "metadata": {},
   "source": [
    "![Left: BoW. Right: LDA](../assets/lda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7018f6c",
   "metadata": {},
   "source": [
    "## The Pipeline\n",
    "\n",
    "1. **Load CVs**: Read all JSON files from topic folders using glob patterns and extract structured fields\n",
    "2. **Preprocess**: Clean the text (remove URLs, emails, etc.)\n",
    "3. **Vectorize**: Convert text to document-term matrix (Bag of Words)\n",
    "4. **Train LDA**: Discover topics automatically\n",
    "5. **Analyze Results**: See what topics were found and which CVs belong to each\n",
    "6. **Organize**: Create folders and copy CVs based on their dominant topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff53c5d",
   "metadata": {},
   "source": [
    "## Step 1: Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e9332f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy==1.26.4 pandas==2.3.3 scikit-learn==1.8.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f5dc104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c1aa196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34 CV files from 3 topic folders:\n",
      "  1. 07\n",
      "  2. 10\n",
      "  3. 11\n",
      "  4. 15\n",
      "  5. 17\n",
      "  6. 20\n",
      "  7. 21\n",
      "  8. 22\n",
      "  9. 26\n",
      "  10. 29\n",
      "  11. 30\n",
      "  12. 33\n",
      "  13. 34\n",
      "  14. 39\n",
      "  15. 40\n",
      "  16. 08\n",
      "  17. 09\n",
      "  18. 12\n",
      "  19. 16\n",
      "  20. 18\n",
      "  21. 19\n",
      "  22. 23\n",
      "  23. 24\n",
      "  24. 31\n",
      "  25. 32\n",
      "  26. 35\n",
      "  27. 36\n",
      "  28. 37\n",
      "  29. 38\n",
      "  30. 13\n",
      "  31. 14\n",
      "  32. 25\n",
      "  33. 27\n",
      "  34. 28\n",
      "\n",
      "Combined structured data into text for 34 CVs\n"
     ]
    }
   ],
   "source": [
    "# Load CVs from JSON files in all topic folders\n",
    "cv_dir = Path('../datasets/CVs')\n",
    "# Use glob pattern to find all JSON files in Topic_* subdirectories, excluding English versions\n",
    "cv_files = sorted([f for f in cv_dir.glob('Topic_*/*.json') if not f.name.endswith('_en.json')])\n",
    "\n",
    "# Load and extract structured data from JSON\n",
    "cvs_data = []\n",
    "cv_names = []\n",
    "cv_file_paths = []  # Store original file paths for later copying\n",
    "\n",
    "for file in cv_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        cvs_data.append(data)\n",
    "        cv_names.append(file.stem)\n",
    "        cv_file_paths.append(file)  # Store the full path\n",
    "\n",
    "print(f\"Loaded {len(cvs_data)} CV files from {len(set(f.parent.name for f in cv_files))} topic folders:\")\n",
    "for i, name in enumerate(cv_names, 1):\n",
    "    print(f\"  {i}. {name}\")\n",
    "\n",
    "# Combine structured fields into text for each CV\n",
    "def combine_cv_fields(cv_json):\n",
    "    \"\"\"Combine Heading, Skills, Projects, Experience, Education into a single text\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Add heading\n",
    "    if 'Heading' in cv_json:\n",
    "        parts.append(cv_json['Heading'])\n",
    "    \n",
    "    # Add skills (join list items)\n",
    "    if 'Skills' in cv_json:\n",
    "        skills_text = ' '.join(cv_json['Skills']) if isinstance(cv_json['Skills'], list) else cv_json['Skills']\n",
    "        parts.append(skills_text)\n",
    "    \n",
    "    # Add projects\n",
    "    if 'Projects' in cv_json:\n",
    "        projects_text = ' '.join(cv_json['Projects']) if isinstance(cv_json['Projects'], list) else cv_json['Projects']\n",
    "        parts.append(projects_text)\n",
    "    \n",
    "    # Add experience\n",
    "    if 'Experience' in cv_json:\n",
    "        exp_text = ' '.join(cv_json['Experience']) if isinstance(cv_json['Experience'], list) else cv_json['Experience']\n",
    "        parts.append(exp_text)\n",
    "    \n",
    "    # Add education\n",
    "    if 'Education' in cv_json:\n",
    "        edu_text = ' '.join(cv_json['Education']) if isinstance(cv_json['Education'], list) else cv_json['Education']\n",
    "        parts.append(edu_text)\n",
    "    \n",
    "    return ' '.join(parts)\n",
    "\n",
    "# Convert JSON data to text\n",
    "cvs = [combine_cv_fields(cv_data) for cv_data in cvs_data]\n",
    "print(f\"\\nCombined structured data into text for {len(cvs)} CVs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbef1b5",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc5c7bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 34 CVs\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean text: remove URLs, emails, and normalize whitespace\"\"\"\n",
    "    # Remove emails and URLs\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Keep only Arabic/English letters and numbers\n",
    "    text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Preprocess all CVs\n",
    "cvs_processed = [preprocess_text(cv) for cv in cvs]\n",
    "print(f\"Preprocessed {len(cvs_processed)} CVs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e1f26b",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for LDA\n",
    "\n",
    "Convert text to a document-term matrix (same as Bag of Words from classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a63cfb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Term Matrix: 34 CVs × 662 words\n",
      "Sparsity: 86.7%\n"
     ]
    }
   ],
   "source": [
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,  # Top 1000 words\n",
    "    min_df=2,           # Word must appear in at least 2 CVs\n",
    "    max_df=0.8          # Ignore words in >80% of CVs\n",
    ")\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform(cvs_processed)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Document-Term Matrix: {doc_term_matrix.shape[0]} CVs × {doc_term_matrix.shape[1]} words\")\n",
    "print(f\"Sparsity: {(1 - doc_term_matrix.nnz / (doc_term_matrix.shape[0] * doc_term_matrix.shape[1])) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29757a7c",
   "metadata": {},
   "source": [
    "## Step 4: Train LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "042a3137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA to discover 3 topics...\n",
      "✓ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model\n",
    "n_topics = 3  # Number of topics to discover\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=10,\n",
    "    learning_method='online'\n",
    ")\n",
    "\n",
    "print(f\"Training LDA to discover {n_topics} topics...\")\n",
    "lda.fit(doc_term_matrix)\n",
    "print(\"✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b719dc1",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Results\n",
    "\n",
    "Let's see what topics LDA discovered and which words define each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58b72bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 1:\n",
      "  Top words: engineer, analyst, analytics, 2019, 2021, business, with, 10, bi, governance\n",
      "  Weights: ['25.418', '25.095', '21.468', '20.625', '19.749', '19.336', '18.298', '16.163', '16.113', '15.502']\n",
      "\n",
      "Topic 2:\n",
      "  Top words: ai, on, models, engineer, research, computer, model, 06, 08, engineering\n",
      "  Weights: ['32.898', '28.287', '22.209', '20.499', '20.153', '20.043', '19.232', '16.574', '16.569', '15.889']\n",
      "\n",
      "Topic 3:\n",
      "  Top words: engineer, spark, big, hadoop, on, aws, platform, 2021, 01, time\n",
      "  Weights: ['7.766', '7.080', '5.884', '5.601', '4.821', '4.686', '4.546', '4.334', '4.237', '4.199']\n"
     ]
    }
   ],
   "source": [
    "# Display top words for each topic\n",
    "def display_topics(model, feature_names, n_top_words=10):\n",
    "    \"\"\"Display top words for each topic\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        top_weights = [topic[i] for i in top_words_idx]\n",
    "        \n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        print(\"  Top words:\", \", \".join(top_words))\n",
    "        print(\"  Weights:\", [f\"{w:.3f}\" for w in top_weights])\n",
    "\n",
    "display_topics(lda, feature_names, n_top_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66088b1",
   "metadata": {},
   "source": [
    "**Interpreting the topics**: Look at the top words for each topic. Can you guess what each topic represents? For example:\n",
    "- Topic with \"PyTorch\", \"TensorFlow\", \"NLP\" → probably AI/ML\n",
    "- Topic with \"Tableau\", \"Power BI\", \"dashboard\" → probably Data Analysis\n",
    "- Topic with \"Hadoop\", \"Spark\", \"Kafka\" → probably Big Data\n",
    "\n",
    "Now let's see which CV belongs to which topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f168fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Assignment to Topics:\n",
      "============================================================\n",
      "\n",
      "Topic 1 (17 CVs):\n",
      "  - 15 (99.4%)\n",
      "  - 29 (99.4%)\n",
      "  - 30 (99.3%)\n",
      "  - 08 (99.4%)\n",
      "  - 09 (99.5%)\n",
      "  - 18 (99.4%)\n",
      "  - 19 (99.4%)\n",
      "  - 23 (75.0%)\n",
      "  - 24 (79.7%)\n",
      "  - 31 (99.2%)\n",
      "  - 35 (99.3%)\n",
      "  - 36 (99.3%)\n",
      "  - 37 (99.3%)\n",
      "  - 38 (99.4%)\n",
      "  - 14 (99.5%)\n",
      "  - 27 (99.4%)\n",
      "  - 28 (99.4%)\n",
      "\n",
      "Topic 2 (14 CVs):\n",
      "  - 07 (99.5%)\n",
      "  - 10 (99.4%)\n",
      "  - 11 (99.5%)\n",
      "  - 17 (99.4%)\n",
      "  - 20 (99.4%)\n",
      "  - 21 (99.4%)\n",
      "  - 22 (99.4%)\n",
      "  - 26 (99.4%)\n",
      "  - 33 (99.4%)\n",
      "  - 34 (99.4%)\n",
      "  - 39 (99.4%)\n",
      "  - 40 (99.4%)\n",
      "  - 13 (84.1%)\n",
      "  - 25 (99.3%)\n",
      "\n",
      "Topic 3 (3 CVs):\n",
      "  - 12 (99.5%)\n",
      "  - 16 (99.3%)\n",
      "  - 32 (99.4%)\n"
     ]
    }
   ],
   "source": [
    "# Get topic distribution for each CV\n",
    "doc_topic_dist = lda.transform(doc_term_matrix)\n",
    "\n",
    "# Find dominant topic for each CV\n",
    "dominant_topics = doc_topic_dist.argmax(axis=1)\n",
    "\n",
    "# Create a DataFrame to see results\n",
    "df_results = pd.DataFrame({\n",
    "    'CV': cv_names,\n",
    "    'Dominant Topic': dominant_topics + 1,\n",
    "    'Topic Probabilities': [dist for dist in doc_topic_dist]\n",
    "})\n",
    "\n",
    "# Show which CVs belong to which topic\n",
    "print(\"CV Assignment to Topics:\")\n",
    "print(\"=\" * 60)\n",
    "for topic_id in range(n_topics):\n",
    "    topic_cvs = df_results[df_results['Dominant Topic'] == topic_id + 1]\n",
    "    print(f\"\\nTopic {topic_id + 1} ({len(topic_cvs)} CVs):\")\n",
    "    for idx, row in topic_cvs.iterrows():\n",
    "        prob = row['Topic Probabilities'][topic_id]\n",
    "        print(f\"  - {row['CV']} ({prob:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086c24a",
   "metadata": {},
   "source": [
    "## Step 6: Organize CVs into Folders\n",
    "\n",
    "Now comes the practical part: **automatically organize CVs into folders** based on their dominant topic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8ee314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 07.json → Topic_2/\n",
      "Copied 10.json → Topic_2/\n",
      "Copied 11.json → Topic_2/\n",
      "Copied 15.json → Topic_1/\n",
      "Copied 17.json → Topic_2/\n",
      "Copied 20.json → Topic_2/\n",
      "Copied 21.json → Topic_2/\n",
      "Copied 22.json → Topic_2/\n",
      "Copied 26.json → Topic_2/\n",
      "Copied 29.json → Topic_1/\n",
      "Copied 30.json → Topic_1/\n",
      "Copied 33.json → Topic_2/\n",
      "Copied 34.json → Topic_2/\n",
      "Copied 39.json → Topic_2/\n",
      "Copied 40.json → Topic_2/\n",
      "Copied 08.json → Topic_1/\n",
      "Copied 09.json → Topic_1/\n",
      "Copied 12.json → Topic_3/\n",
      "Copied 16.json → Topic_3/\n",
      "Copied 18.json → Topic_1/\n",
      "Copied 19.json → Topic_1/\n",
      "Copied 23.json → Topic_1/\n",
      "Copied 24.json → Topic_1/\n",
      "Copied 31.json → Topic_1/\n",
      "Copied 32.json → Topic_3/\n",
      "Copied 35.json → Topic_1/\n",
      "Copied 36.json → Topic_1/\n",
      "Copied 37.json → Topic_1/\n",
      "Copied 38.json → Topic_1/\n",
      "Copied 13.json → Topic_2/\n",
      "Copied 14.json → Topic_1/\n",
      "Copied 25.json → Topic_2/\n",
      "Copied 27.json → Topic_1/\n",
      "Copied 28.json → Topic_1/\n",
      "\n",
      "✓ Organization complete! CVs are now in: output/organized_cvs\n"
     ]
    }
   ],
   "source": [
    "# Create output directory structure\n",
    "output_dir = Path('output/organized_cvs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create a folder for each topic\n",
    "for topic_id in range(n_topics):\n",
    "    topic_dir = output_dir / f\"Topic_{topic_id + 1}\"\n",
    "    topic_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy each CV to its topic folder\n",
    "for idx, (cv_name, topic_id, source_file) in enumerate(zip(cv_names, dominant_topics, cv_file_paths)):\n",
    "    target_dir = output_dir / f\"Topic_{topic_id + 1}\"\n",
    "    target_file = target_dir / f\"{cv_name}.json\"\n",
    "    \n",
    "    shutil.copy2(source_file, target_file)\n",
    "    print(f\"Copied {cv_name}.json → Topic_{topic_id + 1}/\")\n",
    "\n",
    "print(f\"\\n✓ Organization complete! CVs are now in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed5be03",
   "metadata": {},
   "source": [
    "### Verify the Organization\n",
    "\n",
    "Let's check what's in each folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "445a901c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic_1/ (17 CVs):\n",
      "  - 08.json\n",
      "  - 09.json\n",
      "  - 14.json\n",
      "  - 15.json\n",
      "  - 18.json\n",
      "  - 19.json\n",
      "  - 23.json\n",
      "  - 24.json\n",
      "  - 27.json\n",
      "  - 28.json\n",
      "  - 29.json\n",
      "  - 30.json\n",
      "  - 31.json\n",
      "  - 35.json\n",
      "  - 36.json\n",
      "  - 37.json\n",
      "  - 38.json\n",
      "\n",
      "Topic_2/ (14 CVs):\n",
      "  - 07.json\n",
      "  - 10.json\n",
      "  - 11.json\n",
      "  - 13.json\n",
      "  - 17.json\n",
      "  - 20.json\n",
      "  - 21.json\n",
      "  - 22.json\n",
      "  - 25.json\n",
      "  - 26.json\n",
      "  - 33.json\n",
      "  - 34.json\n",
      "  - 39.json\n",
      "  - 40.json\n",
      "\n",
      "Topic_3/ (3 CVs):\n",
      "  - 12.json\n",
      "  - 16.json\n",
      "  - 32.json\n"
     ]
    }
   ],
   "source": [
    "# Show contents of each topic folder\n",
    "for topic_id in range(n_topics):\n",
    "    topic_dir = output_dir / f\"Topic_{topic_id + 1}\"\n",
    "    files = list(topic_dir.glob('*.json'))\n",
    "    print(f\"\\nTopic_{topic_id + 1}/ ({len(files)} CVs):\")\n",
    "    for f in sorted(files):\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48759d",
   "metadata": {},
   "source": [
    "## **Student Exercise**: discover topics on a dataset of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffffa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "46913c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  \\\n",
       "0  I was wondering if anyone out there could enli...         7   \n",
       "1  A fair number of brave souls who upgraded thei...         4   \n",
       "2  well folks, my mac plus finally gave up the gh...         4   \n",
       "3  \\nDo you have Weitek's address/phone number?  ...         1   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...        14   \n",
       "\n",
       "           category_name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': data.data,\n",
    "    'category': data.target,\n",
    "    'category_name': [data.target_names[data.target[i]] for i in range(len(data.target))]\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b72940dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.lower().strip()\n",
    "\n",
    "\n",
    "df['texts_clean'] = df['text'].apply(preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "616460dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words='english',\n",
    "    max_features=1000,\n",
    "    max_df=0.9,\n",
    "    min_df=2,\n",
    "    token_pattern=r'\\b[a-zA-Z]{3,}\\b'\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['texts_clean'])\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cec7a0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-14.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-14.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-14 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-14 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-14 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-14 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-14 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-14 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-14 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-14 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, n_components=8,\n",
       "                          random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=n_components,-int%2C%20default%3D10\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=10<br><br>Number of topics.<br><br>.. versionchanged:: 0.19<br>    ``n_topics`` was renamed to ``n_components``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('doc_topic_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=doc_topic_prior,-float%2C%20default%3DNone\">\n",
       "            doc_topic_prior\n",
       "            <span class=\"param-doc-description\">doc_topic_prior: float, default=None<br><br>Prior of document topic distribution `theta`. If the value is None,<br>defaults to `1 / n_components`.<br>In [1]_, this is called `alpha`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('topic_word_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=topic_word_prior,-float%2C%20default%3DNone\">\n",
       "            topic_word_prior\n",
       "            <span class=\"param-doc-description\">topic_word_prior: float, default=None<br><br>Prior of topic word distribution `beta`. If the value is None, defaults<br>to `1 / n_components`.<br>In [1]_, this is called `eta`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_method,-%7B%27batch%27%2C%20%27online%27%7D%2C%20default%3D%27batch%27\">\n",
       "            learning_method\n",
       "            <span class=\"param-doc-description\">learning_method: {'batch', 'online'}, default='batch'<br><br>Method used to update `_component`. Only used in :meth:`fit` method.<br>In general, if the data size is large, the online update will be much<br>faster than the batch update.<br><br>Valid options:<br><br>- 'batch': Batch variational Bayes method. Use all training data in each EM<br>  update. Old `components_` will be overwritten in each iteration.<br>- 'online': Online variational Bayes method. In each EM update, use mini-batch<br>  of training data to update the ``components_`` variable incrementally. The<br>  learning rate is controlled by the ``learning_decay`` and the<br>  ``learning_offset`` parameters.<br><br>.. versionchanged:: 0.20<br>    The default learning method is now ``\"batch\"``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;online&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_decay',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_decay,-float%2C%20default%3D0.7\">\n",
       "            learning_decay\n",
       "            <span class=\"param-doc-description\">learning_decay: float, default=0.7<br><br>It is a parameter that control learning rate in the online learning<br>method. The value should be set between (0.5, 1.0] to guarantee<br>asymptotic convergence. When the value is 0.0 and batch_size is<br>``n_samples``, the update method is same as batch learning. In the<br>literature, this is called kappa.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_offset',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_offset,-float%2C%20default%3D10.0\">\n",
       "            learning_offset\n",
       "            <span class=\"param-doc-description\">learning_offset: float, default=10.0<br><br>A (positive) parameter that downweights early iterations in online<br>learning.  It should be greater than 1.0. In the literature, this is<br>called tau_0.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=max_iter,-int%2C%20default%3D10\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=10<br><br>The maximum number of passes over the training data (aka epochs).<br>It only impacts the behavior in the :meth:`fit` method, and not the<br>:meth:`partial_fit` method.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('batch_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=batch_size,-int%2C%20default%3D128\">\n",
       "            batch_size\n",
       "            <span class=\"param-doc-description\">batch_size: int, default=128<br><br>Number of documents to use in each EM iteration. Only used in online<br>learning.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">128</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('evaluate_every',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=evaluate_every,-int%2C%20default%3D-1\">\n",
       "            evaluate_every\n",
       "            <span class=\"param-doc-description\">evaluate_every: int, default=-1<br><br>How often to evaluate perplexity. Only used in `fit` method.<br>set it to 0 or negative number to not evaluate perplexity in<br>training at all. Evaluating perplexity can help you check convergence<br>in training process, but it will also increase total training time.<br>Evaluating perplexity in every iteration might increase training time<br>up to two-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('total_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=total_samples,-int%2C%20default%3D1e6\">\n",
       "            total_samples\n",
       "            <span class=\"param-doc-description\">total_samples: int, default=1e6<br><br>Total number of documents. Only used in the :meth:`partial_fit` method.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000000.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('perp_tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=perp_tol,-float%2C%20default%3D1e-1\">\n",
       "            perp_tol\n",
       "            <span class=\"param-doc-description\">perp_tol: float, default=1e-1<br><br>Perplexity tolerance. Only used when ``evaluate_every`` is greater than 0.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('mean_change_tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=mean_change_tol,-float%2C%20default%3D1e-3\">\n",
       "            mean_change_tol\n",
       "            <span class=\"param-doc-description\">mean_change_tol: float, default=1e-3<br><br>Stopping tolerance for updating document topic distribution in E-step.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_doc_update_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=max_doc_update_iter,-int%2C%20default%3D100\">\n",
       "            max_doc_update_iter\n",
       "            <span class=\"param-doc-description\">max_doc_update_iter: int, default=100<br><br>Max number of iterations for updating document topic distribution in<br>the E-step.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use in the E-step.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Verbosity level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Pass an int for reproducible results across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-14');</script></body>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', n_components=8,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "num_topics = 8\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=num_topics,\n",
    "    random_state=42,\n",
    "    max_iter=10,\n",
    "    learning_method='online'\n",
    ")\n",
    "\n",
    "lda.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6ba79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 1:\n",
      "good, new, used, like, time, best, book, price, does, original\n",
      "\n",
      "Topic 2:\n",
      "don, just, people, know, think, like, does, way, say, right\n",
      "\n",
      "Topic 3:\n",
      "file, program, windows, use, available, files, mail, window, software, ftp\n",
      "\n",
      "Topic 4:\n",
      "key, use, information, encryption, chip, public, keys, clipper, number, used\n",
      "\n",
      "Topic 5:\n",
      "year, game, team, car, play, games, new, got, years, good\n",
      "\n",
      "Topic 6:\n",
      "max, drive, card, disk, scsi, dos, mac, bit, video, memory\n",
      "\n",
      "Topic 7:\n",
      "god, people, jesus, said, bible, armenian, christian, jews, life, did\n",
      "\n",
      "Topic 8:\n",
      "space, government, president, national, state, new, gun, states, american, university\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def display_topics(model, feature_names, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        words = [feature_names[i] for i in top_words_idx]\n",
    "        \n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        print(\", \".join(words))\n",
    "\n",
    "display_topics(lda, feature_names, n_top_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f9acf83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dominant_topic\n",
       "1    1760\n",
       "2    3938\n",
       "3    1415\n",
       "4     398\n",
       "5    1304\n",
       "6     873\n",
       "7     877\n",
       "8     749\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist = lda.transform(X)\n",
    "\n",
    "dominant_topic = doc_topic_dist.argmax(axis=1) \n",
    "\n",
    "\n",
    "df['dominant_topic'] = dominant_topic\n",
    "df['dominant_topic'] = df['dominant_topic'] + 1\n",
    "\n",
    "\n",
    "df['dominant_topic'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0e635224",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = {\n",
    "    1 : 'Reviews',\n",
    "    2 : 'General Discussion',\n",
    "    3 : 'Software & Files',\n",
    "    4 : 'Security',\n",
    "    5 : 'Sports',\n",
    "    6 : 'Computer',\n",
    "    7 : 'Religion',\n",
    "    8 : 'Politics'\n",
    "\n",
    "}\n",
    "\n",
    "df['topic_names'] = df['dominant_topic'].map(topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3c8a7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Topic: 1 - Reviews\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "I have a line on a Ducati 900GTS 1978 model with 17k on the clock.  Runs\n",
      "very well, paint is the bronze/brown/orange faded out, leaks a bit of oil\n",
      "and pops out of 1st with hard accel.  The shop will fix trans and oil \n",
      "leak.  They sold the bike to the 1 and only owner.  They want $3495, and\n",
      "I am thinking more like $3K.  Any opinions out there?  Please email me.\n",
      "Thanks.  It would be a nice stable mate to the Beemer.  Then I'll get\n",
      "a jap bike and call myself Axis Motors!\n",
      "\n",
      "-- \n",
      "----------------------\n",
      "\n",
      "--- Example2 ---\n",
      "--\n",
      "\n",
      "\n",
      "--- Example3 ---\n",
      "Reduced Prices! \n",
      "I have a list of things forsale on behalf of my brother, who's moving (moved\n",
      "already)\n",
      "\n",
      "\t\t\t\t\t\t\t\tOffer:\n",
      "1) Black and Decker Duster Plus (Portable Hand Vaccum)\t\n",
      " \tpurchased for $32, \t\t\t\t\t  $12\n",
      "\n",
      "2) SR-1000 Dual Cassette Portable Player, AM/FM\n",
      "5-Band graphics Equalizer, high speed dubing, Duo \n",
      "Tape.Tape deck A, seems to have lost treble sound. \n",
      "But, I bet  it's fixable.\n",
      "\tpurchased for $80\t\t\t\t\t  $25\n",
      "\n",
      "3)Monolux Zoom MicroScope, up to 1200X magnification\n",
      "Made in Japan, includes case and\n",
      "\n",
      "================================================================================\n",
      "Topic: 2 - General Discussion\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "well folks, my mac plus finally gave up the ghost this weekend after\n",
      "starting life as a 512k way back in 1985.  sooo, i'm in the market for a\n",
      "new machine a bit sooner than i intended to be...\n",
      "\n",
      "i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\n",
      "of questions that (hopefully) somebody can answer:\n",
      "\n",
      "* does anybody know any dirt on when the next round of powerbook\n",
      "introductions are expected?  i'd heard the 185c was supposed to make an\n",
      "appearence \"this summer\" but haven't heard a\n",
      "\n",
      "--- Example2 ---\n",
      "From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\n",
      "\n",
      "\n",
      "My understanding is that the 'expected errors' are basically\n",
      "known bugs in the warning system software - things are checked\n",
      "that don't have the right values in yet because they aren't\n",
      "set till after launch, and suchlike. Rather than fix the code\n",
      "and possibly introduce new bugs, they just tell the crew\n",
      "'ok, if you see a warning no. 213 before liftoff, ignore it'.\n",
      "\n",
      "--- Example3 ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Of course.  The term must be rigidly defined in any bill.\n",
      "\n",
      "\n",
      "I doubt she uses this term for that.  You are using a quote allegedly\n",
      "from her, can you back it up?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I read the article as presenting first an argument about weapons of mass\n",
      "destruction (as commonly understood) and then switching to other topics.\n",
      "The first point evidently was to show that not all weapons should be\n",
      "allowed, and then the later analysis was, given this understanding, to\n",
      "consider another class.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Topic: 3 - Software & Files\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "There were a few people who responded to my request for info on\n",
      "treatment for astrocytomas through email, whom I couldn't thank\n",
      "directly because of mail-bouncing probs (Sean, Debra, and Sharon).  So\n",
      "I thought I'd publicly thank everyone.\n",
      "\n",
      "Thanks! \n",
      "\n",
      "(I'm sure glad I accidentally hit \"rn\" instead of \"rm\" when I was\n",
      "trying to delete a file last September. \"Hmmm... 'News?' What's\n",
      "this?\"....)\n",
      "\n",
      "--- Example2 ---\n",
      "I have win 3.0 and downloaded several icons and BMP's but I can't figure out\n",
      "how to change the \"wallpaper\" or use the icons.  Any help would be appreciated.\n",
      "\n",
      "\n",
      "Thanx,\n",
      "\n",
      "-Brando\n",
      "\n",
      "--- Example3 ---\n",
      "QUESTION:\n",
      "  What is the EXACT entry (parameter and syntax please), in the X-Terminal\n",
      "configuration file (loaded when the X-Terminal boots), to add another system \n",
      "to the TCP/IP access control list?   \n",
      "\n",
      "  BACKGROUND:\n",
      "  I have two unix systems, 1. an AT&T 3B2 running X11R3 and MIT's X11R4 and \n",
      "2. a Sun SS10 without any X.  \n",
      "  I want to have a window to the Sun and the 3B2 on the NCD X-Terminal at the\n",
      "same time.  I can do this if I manually set the Network Parameter TCP/IP\n",
      "Access Control List to of\n",
      "\n",
      "================================================================================\n",
      "Topic: 4 - Security\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "\n",
      "Do you have Weitek's address/phone number?  I'd like to get some information\n",
      "about this chip.\n",
      "\n",
      "\n",
      "--- Example2 ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The control box of the Window itself (upper left corner of the window, single\n",
      "click, am I being too simplistic?) has a font option. The 8 X 12 is about the\n",
      "biggest one I can use without the characters turning funky. \n",
      "\n",
      "--- Example3 ---\n",
      "Hey now,\n",
      "\n",
      "The following cds are still available. Offers/trades considered.\n",
      "\n",
      "Gowan - Lost Brotherhood\n",
      "Katrina & the Waves - Break of Hearts\n",
      "Joe Cocker - Live\n",
      "Charles Neville - Diversity\n",
      "\n",
      "================================================================================\n",
      "Topic: 5 - Sports\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "--- Example2 ---\n",
      "I recently posted an article asking what kind of rates single, male\n",
      "drivers under 25 yrs old were paying on performance cars. Here's a summary of\n",
      "the replies I received.\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "-------------------------------------------------------------------------------\n",
      " \n",
      "I'm not under 25 anymore (but is 27 close enough).\n",
      " \n",
      "1992 Dodge Stealth RT/Twin Turbo (300hp model).\n",
      "No tickets, no accidents, own a house, have taken defensive driving 1,\n",
      "airbag, abs, security alarm, single.\n",
      " \n",
      "$1500/year  $500 decut. State\n",
      "\n",
      "--- Example3 ---\n",
      "\n",
      "I think that Mike Foligno was the captain of the Sabres when he\n",
      "got traded to the Leafs. Also, wasn't Rick Vaive the captain of\n",
      "the Leafs when he got traded to Chicago (with Steve Thomas for\n",
      "Ed Olcyzk and someone). Speaking of the Leafs, I believe that\n",
      "Darryl Sittler was their captain (he'd torn the \"C\" off his\n",
      "jersey but I think he re-claimed the captaincy later on) when he\n",
      "was traded to the Flyers.\n",
      "\n",
      "Oh yeah, of course, Gretzky was the captain of the Oilers before\n",
      "he was traded wasn't he? \n",
      "\n",
      "================================================================================\n",
      "Topic: 6 - Computer\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven\n",
      "\n",
      "--- Example2 ---\n",
      "                                                                      \n",
      "ALL this shows is that YOU don't know much about SCSI.\n",
      "\n",
      "SCSI-1 {with a SCSI-1 controler chip} range is indeed 0-5MB/s\n",
      "and that is ALL you have right about SCSI\n",
      "SCSI-1 {With a SCSI-2 controller chip}: 4-6MB/s with 10MB/s burst {8-bit}\n",
      " Note the INCREASE in SPEED, the Mac Quadra uses this version of SCSI-1\n",
      " so it DOES exist. Some PC use this set up too.\n",
      "SCSI-2 {8-bit/SCSI-1 mode}:          4-6MB/s with 10MB/s burst\n",
      "SCSI-2 {16-b\n",
      "\n",
      "--- Example3 ---\n",
      "\n",
      "\n",
      "\n",
      "I've had the board for over a year, and it does work with Diskdoubler,\n",
      "but not with Autodoubler, due to a licensing problem with Stac Technologies,\n",
      "the owners of the board's compression technology. (I'm writing this\n",
      "from memory; I've lost the reference. Please correct me if I'm wrong.)\n",
      "\n",
      "Using the board, I've had problems with file icons being lost, but it's\n",
      "hard to say whether it's the board's fault or something else; however,\n",
      "if I decompress the troubled file and recompress it without the bo\n",
      "\n",
      "================================================================================\n",
      "Topic: 7 - Religion\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "\n",
      "Yep, that's pretty much it. I'm not a Jew but I understand that this is the\n",
      "Jewish way of thinking. However, the Jews believe that the Covenant between\n",
      "YHWH and the Patriarchs (Abraham and Moses, in this case) establishes a Moral\n",
      "Code to follow for mankind. Even the Jews could not decide where the boundaries\n",
      "fall, though.\n",
      "\n",
      "As I understand it, the Sadducees believed that the Torah was all that was\n",
      "required, whereas the Pharisees (the ancestors of modern Judaism) believed that\n",
      "the Torah was avail\n",
      "\n",
      "--- Example2 ---\n",
      "\n",
      "Yes.\n",
      "\n",
      "(I am adamantly an environmentalist.  I will not use styrofoam table service.\n",
      "Please keep that in mind as you read this post - I do not wish to attack\n",
      "environmentalism)\n",
      "\n",
      "A half truth is at least as dangerous as a complete lie.  A complete lie will\n",
      "rarely be readily accepted, while a half truth (the lie subtly hidden) is more\n",
      "powerfully offered by one who masquerades as an angel of light.\n",
      "\n",
      "Satan has (for some people) loosened the grip on treating the earth as something\n",
      "other than God's int\n",
      "\n",
      "--- Example3 ---\n",
      "\n",
      "Once again, it appears that the one-eyed man has appeared in the land of the sighted\n",
      "and for some strange resaon has appointed himself the ruler and supreme power.\n",
      "\n",
      "================================================================================\n",
      "Topic: 8 - Politics\n",
      "================================================================================\n",
      "\n",
      "--- Example1 ---\n",
      "\n",
      "   {Description of \"External Tank\" option for SSF redesign deleted}\n",
      "\n",
      "\n",
      "Yo Ken, let's keep on-top of things! Both the \"External Tank\" and\n",
      "\"Wingless Orbiter\" options have been deleted from the SSF redesign\n",
      "options list. Today's (4/23) edition of the New York Times reports\n",
      "that O'Connor told the panel that some redesign proposals have\n",
      "been dropped, such as using the \"giant external fuel tanks used\n",
      "in launching space shuttles,\" and building a \"station around\n",
      "an existing space shuttle with its wings \n",
      "\n",
      "--- Example2 ---\n",
      "\n",
      "       Actually, fossil fuel plants run hotter than the usual \n",
      "boiling-water reactor nuclear plants.  (There's a gripe in the industry\n",
      "that nuclear power uses 1900 vintage steam technology).  So it's\n",
      "more important in nuclear plants to get the cold end of the system\n",
      "as cold as possible.  Hence big cooling towers.  \n",
      "\n",
      "       Oil and gas fired steam plants also have condensers, but they\n",
      "usually are sized to get the steam back into hot water, not most of the\n",
      "way down to ambient.  Some plants do coo\n",
      "\n",
      "--- Example3 ---\n",
      " Just as a not of possible interest on this subject ..\n",
      "It is my understanding that exploding televisions were a major cause of\n",
      "domestic accidents in the Soviet Union in past years!\n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in sorted(df['dominant_topic'].unique()):\n",
    "    print('\\n'+ '='*80)\n",
    "    print(f\"Topic: {t} - {topic_names.get(t,'Unknown')}\")\n",
    "    print('='*80)\n",
    "\n",
    "    sample_texts = df[df['dominant_topic']==t].head(3)['text']\n",
    "\n",
    "    for i, txt in enumerate(sample_texts, 1):\n",
    "        print(f'\\n--- Example{i} ---')\n",
    "        print(txt[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eced730d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "      <th>texts_clean</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>topic_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>i was wondering if anyone out there could enli...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>a fair number of brave souls who upgraded thei...</td>\n",
       "      <td>6</td>\n",
       "      <td>Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>well folks my mac plus finally gave up the gho...</td>\n",
       "      <td>2</td>\n",
       "      <td>General Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>do you have weitek s address phone number i d ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>from article by tom a baker my understanding i...</td>\n",
       "      <td>2</td>\n",
       "      <td>General Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>dn from david nye dn a neurology dn consultati...</td>\n",
       "      <td>2</td>\n",
       "      <td>General Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>I have a (very old) Mac 512k and a Mac Plus, b...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>i have a very old mac k and a mac plus both of...</td>\n",
       "      <td>6</td>\n",
       "      <td>Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>i just installed a dx cpu in a clone motherboa...</td>\n",
       "      <td>2</td>\n",
       "      <td>General Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>wouldn t this require a hyper sphere in space ...</td>\n",
       "      <td>2</td>\n",
       "      <td>General Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>Stolen from Pasadena between 4:30 and 6:30 pm ...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>stolen from pasadena between and pm on blue an...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "0      I was wondering if anyone out there could enli...         7   \n",
       "1      A fair number of brave souls who upgraded thei...         4   \n",
       "2      well folks, my mac plus finally gave up the gh...         4   \n",
       "3      \\nDo you have Weitek's address/phone number?  ...         1   \n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...        14   \n",
       "...                                                  ...       ...   \n",
       "11309  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...        13   \n",
       "11310  I have a (very old) Mac 512k and a Mac Plus, b...         4   \n",
       "11311  I just installed a DX2-66 CPU in a clone mothe...         3   \n",
       "11312  \\nWouldn't this require a hyper-sphere.  In 3-...         1   \n",
       "11313  Stolen from Pasadena between 4:30 and 6:30 pm ...         8   \n",
       "\n",
       "                  category_name  \\\n",
       "0                     rec.autos   \n",
       "1         comp.sys.mac.hardware   \n",
       "2         comp.sys.mac.hardware   \n",
       "3                 comp.graphics   \n",
       "4                     sci.space   \n",
       "...                         ...   \n",
       "11309                   sci.med   \n",
       "11310     comp.sys.mac.hardware   \n",
       "11311  comp.sys.ibm.pc.hardware   \n",
       "11312             comp.graphics   \n",
       "11313           rec.motorcycles   \n",
       "\n",
       "                                             texts_clean  dominant_topic  \\\n",
       "0      i was wondering if anyone out there could enli...               5   \n",
       "1      a fair number of brave souls who upgraded thei...               6   \n",
       "2      well folks my mac plus finally gave up the gho...               2   \n",
       "3      do you have weitek s address phone number i d ...               4   \n",
       "4      from article by tom a baker my understanding i...               2   \n",
       "...                                                  ...             ...   \n",
       "11309  dn from david nye dn a neurology dn consultati...               2   \n",
       "11310  i have a very old mac k and a mac plus both of...               6   \n",
       "11311  i just installed a dx cpu in a clone motherboa...               2   \n",
       "11312  wouldn t this require a hyper sphere in space ...               2   \n",
       "11313  stolen from pasadena between and pm on blue an...               5   \n",
       "\n",
       "              topic_names  \n",
       "0                  Sports  \n",
       "1                Computer  \n",
       "2      General Discussion  \n",
       "3                Security  \n",
       "4      General Discussion  \n",
       "...                   ...  \n",
       "11309  General Discussion  \n",
       "11310            Computer  \n",
       "11311  General Discussion  \n",
       "11312  General Discussion  \n",
       "11313              Sports  \n",
       "\n",
       "[11314 rows x 6 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213d4f9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we accomplished**:\n",
    "1. ✅ Loaded unlabeled CVs from a folder\n",
    "2. ✅ Preprocessed the text data\n",
    "3. ✅ Created a document-term matrix\n",
    "4. ✅ Trained an LDA model to discover topics\n",
    "5. ✅ Analyzed which CVs belong to which topic\n",
    "6. ✅ **Automatically organized CVs into folders** based on discovered topics\n",
    "\n",
    "**Key Takeaways**:\n",
    "- **LDA discovers topics automatically** by finding words that co-occur together\n",
    "- **Each document is a mixture of topics** - LDA assigns probabilities\n",
    "- **Topic modeling is unsupervised** - no labels needed!\n",
    "- **Practical application**: Organize unlabeled documents automatically\n",
    "\n",
    "**Next Steps**:\n",
    "- Try different numbers of topics (`n_topics`) and see how results change\n",
    "- Experiment with preprocessing (stemming, stop words removal)\n",
    "- Use topic probabilities to handle CVs that belong to multiple topics\n",
    "- Visualize topics using tools like pyLDAvis\n",
    "\n",
    "**References**:\n",
    "- [Scikit-learn LDA documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)\n",
    "- [Topic modeling visualization guide](https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8790015",
   "metadata": {},
   "source": [
    "\n",
    "## Module 1 Synthesis: The Complete Pipeline\n",
    "\n",
    "Congratulations! You've completed **Module 1: Text Analysis with Statistical NLP**. Let's reflect on the journey and see how all the pieces fit together.\n",
    "\n",
    "### The Circular Learning Experience\n",
    "\n",
    "Remember the question chain we started with? Let's trace how we answered each question and built a complete NLP pipeline:\n",
    "\n",
    "1. **\"What is NLP?\"** → We learned that NLP bridges computers and human language, with applications in understanding and generation.\n",
    "\n",
    "2. **\"How do we extract patterns from text?\"** → We used **Regular Expressions** to find, match, and manipulate text patterns—essential for preprocessing.\n",
    "\n",
    "3. **\"How do we understand our data?\"** → We performed **Exploratory Data Analysis (EDA)** on corpora to assess data quality, vocabulary characteristics, and preprocessing needs.\n",
    "\n",
    "4. **\"How do we prepare text for ML?\"** → We applied **Preprocessing** techniques (cleaning, normalization, tokenization, stemming) to transform raw text into clean tokens.\n",
    "\n",
    "5. **\"How do we convert text to numbers?\"** → We used **Vectorization** (BoW, TF-IDF) to convert text into numerical features that ML models can process.\n",
    "\n",
    "6. **\"How do we build classifiers?\"** → We built **Text Classification** models (like sentiment analysis) using vectorized features and supervised learning.\n",
    "\n",
    "7. **\"How do we search documents?\"** → We implemented **Information Retrieval** systems using TF-IDF and cosine similarity to find relevant documents.\n",
    "\n",
    "8. **\"How do we discover topics?\"** → We applied **Topic Modeling** (LDA) to automatically organize unlabeled documents by discovering hidden topics.\n",
    "\n",
    "### The Complete NLP Pipeline\n",
    "\n",
    "Throughout this module, you've learned to build a complete NLP pipeline:\n",
    "\n",
    "```\n",
    "Raw Text\n",
    "    ↓\n",
    "[Regex: Pattern Extraction]\n",
    "    ↓\n",
    "[Corpus & EDA: Understanding Data]\n",
    "    ↓\n",
    "[Preprocessing: Cleaning & Normalization]\n",
    "    ↓\n",
    "[Vectorization: Text → Numbers]\n",
    "    ↓\n",
    "[Modeling: Classification / IR / Topic Modeling]\n",
    "    ↓\n",
    "Actionable Insights\n",
    "```\n",
    "\n",
    "### Key Skills You've Acquired\n",
    "\n",
    "By completing this module, you can now:\n",
    "\n",
    "✅ **Build supervised ML text classification pipelines**\n",
    "- Preprocess Arabic and English text\n",
    "- Vectorize text using BoW and TF-IDF\n",
    "- Train and evaluate classifiers\n",
    "- Interpret model results\n",
    "\n",
    "✅ **Apply keyword-based information retrieval**\n",
    "- Implement TF-IDF-based search engines\n",
    "- Measure document similarity using cosine similarity\n",
    "- Rank and retrieve relevant documents\n",
    "\n",
    "✅ **Apply unsupervised ML for document organization**\n",
    "- Discover hidden topics using LDA\n",
    "- Organize unlabeled documents automatically\n",
    "- Interpret topic modeling results\n",
    "\n",
    "### The Foundation for What's Next\n",
    "\n",
    "This module focused on **statistical NLP**—traditional methods that work well for many tasks. In **Module 2**, you'll learn about **Deep Learning approaches** (embeddings, transformers) that build on these foundations to achieve even better performance.\n",
    "\n",
    "**What you learned here is still valuable:**\n",
    "- Preprocessing techniques apply to both statistical and deep learning methods\n",
    "- Understanding vectorization helps you understand embeddings\n",
    "- EDA is always the first step, regardless of the approach\n",
    "- The pipeline structure (preprocess → vectorize → model) remains the same\n",
    "\n",
    "### Reflection Questions\n",
    "\n",
    "Before moving to Module 2, consider:\n",
    "\n",
    "1. **When would you use statistical NLP vs. deep learning?**\n",
    "   - Statistical NLP: Fast, interpretable, works with small data\n",
    "   - Deep Learning: Better accuracy, requires more data and computation\n",
    "\n",
    "2. **What preprocessing steps are most important?**\n",
    "   - Depends on your data and task, but EDA always guides the decision\n",
    "\n",
    "3. **How does TF-IDF differ from BoW?**\n",
    "   - BoW: Simple word counts\n",
    "   - TF-IDF: Weighted counts that emphasize distinctive words\n",
    "\n",
    "4. **When would you use topic modeling vs. classification?**\n",
    "   - Classification: When you have labels and want to predict categories\n",
    "   - Topic Modeling: When you have no labels and want to discover structure\n",
    "\n",
    "### The Journey Continues\n",
    "\n",
    "You've built a solid foundation in statistical NLP. The concepts you've learned—preprocessing, vectorization, classification, retrieval, and topic modeling—are the building blocks for more advanced techniques.\n",
    "\n",
    "**Next Module Preview:**\n",
    "- **Module 2** introduces **Deep Learning for NLP**:\n",
    "  - Tokenization with modern tools (WordPiece, BPE)\n",
    "  - Word embeddings (Word2Vec, GloVe, contextual embeddings)\n",
    "  - Transformers and BERT\n",
    "  - Fine-tuning pre-trained models\n",
    "\n",
    "The journey from statistical NLP to deep learning is a natural progression—you'll see how embeddings generalize vectorization, how transformers improve on traditional methods, and how pre-trained models leverage the foundations you've built.\n",
    "\n",
    "---\n",
    "\n",
    "**Module 1 Complete! 🎉**\n",
    "\n",
    "You now have the skills to work with text data using statistical methods. You understand the complete pipeline from raw text to actionable insights, and you're ready to explore the power of deep learning in Module 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w5-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
